import PyPDF2
from nltk.tokenize import sent_tokenize

def extract_climate_summary(pdf_path):
    # Open the PDF file
    with open(pdf_path, 'rb') as file:
        # Create a PDF reader object
        pdf_reader = PyPDF2.PdfFileReader(file)

        # Extract text from each page
        text = ""
        for page_num in range(pdf_reader.numPages):
            page = pdf_reader.getPage(page_num)
            text += page.extractText()

        # Tokenize the text into sentences
        sentences = sent_tokenize(text)

        # Look for sentences containing climate-related keywords
        climate_keywords = ['climate', 'global warming', 'carbon emissions', 'greenhouse gases']
        climate_sentences = []
        for sentence in sentences:
            if any(keyword in sentence.lower() for keyword in climate_keywords):
                climate_sentences.append(sentence)

        # Generate a summary from the climate-related sentences
        summary = ' '.join(climate_sentences)

        return summary

# Provide the path to the ESG company PDF document
pdf_path = 'path/to/esg_company_report.pdf'

# Extract the climate-related summary
climate_summary = extract_climate_summary(pdf_path)

# Print the summary
print(climate_summary)
